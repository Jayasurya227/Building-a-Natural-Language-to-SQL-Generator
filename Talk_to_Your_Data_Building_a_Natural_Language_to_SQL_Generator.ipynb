{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyMvGwMCpQrcj3wzfmfWeKjD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayasurya227/Building-a-Natural-Language-to-SQL-Generator/blob/main/Talk_to_Your_Data_Building_a_Natural_Language_to_SQL_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Recive Data**"
      ],
      "metadata": {
        "id": "KgxiBGyZvnbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! curl \"https://api.mockaroo.com/api/dde01370?count=1000&key=11149690\" > \"/content/customers.csv\""
      ],
      "metadata": {
        "id": "v7mRik68GVHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8997a752-ece2-44dc-dbb9-83d1b9a4e64f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 99118    0 99118    0     0  60242      0 --:--:--  0:00:01 --:--:-- 60254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! curl \"https://api.mockaroo.com/api/8ba6f630?count=1000&key=11149690\" > \"/content/products.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXd4pF6wu44P",
        "outputId": "ec3b4ca7-f482-46e0-b21c-618f3c1ee6c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  682k    0  682k    0     0   285k      0 --:--:--  0:00:02 --:--:--  285k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! curl \"https://api.mockaroo.com/api/8ba6f630?count=1000&key=11149690\" > \"/content/orders.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUP5k103vBw5",
        "outputId": "d037ad16-ac1c-4563-af3b-aec9073096c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  695k    0  695k    0     0   293k      0 --:--:--  0:00:02 --:--:--  293k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:Setup DataBase**"
      ],
      "metadata": {
        "id": "RW3I3Qdrv4PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "-p1A-1XRv9Jx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define SQL schemas for creating tables\n",
        "customers_schema = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS customers (\n",
        "    customer_id INT PRIMARY KEY,\n",
        "    first_name VARCHAR(50),\n",
        "    last_name VARCHAR(50),\n",
        "    email VARCHAR(50),\n",
        "    phone_number VARCHAR(50),\n",
        "    address VARCHAR(50),\n",
        "    city VARCHAR(50),\n",
        "    country VARCHAR(50),\n",
        "    postal_code VARCHAR(50),\n",
        "    loyalty_points INT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "products_schema = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS products (\n",
        "    product_id INT PRIMARY KEY,\n",
        "    product_name TEXT,\n",
        "    description TEXT,\n",
        "    price DECIMAL(10,2),\n",
        "    discount_percentage DECIMAL(5,2),\n",
        "    category VARCHAR(50),\n",
        "    brand TEXT,\n",
        "    stock_quantity INT,\n",
        "    color VARCHAR(50),\n",
        "    size VARCHAR(20),\n",
        "    weight DECIMAL(5,2),\n",
        "    dimensions TEXT,\n",
        "    release_date DATE,\n",
        "    rating DECIMAL(3,1),\n",
        "    reviews_count INT,\n",
        "    seller_name TEXT,\n",
        "    seller_rating DECIMAL(3,1),\n",
        "    seller_reviews_count INT,\n",
        "    shipping_method VARCHAR(20),\n",
        "    shipping_cost DECIMAL(6,2)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "orders_schema = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS orders (\n",
        "    order_id INT PRIMARY KEY,\n",
        "    customer_id INT,\n",
        "    product_id INT,\n",
        "    quantity INT,\n",
        "    unit_price DECIMAL(10,2),\n",
        "    total_price DECIMAL(10,2),\n",
        "    order_date DATE,\n",
        "    shipping_address VARCHAR(255),\n",
        "    payment_method VARCHAR(20),\n",
        "    status VARCHAR(20),\n",
        "    FOREIGN KEY (customer_id) REFERENCES customers(customer_id),\n",
        "    FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        ");\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ANWN99wswDdO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_name = 'ecommerce.db'\n",
        "if os.path.exists(db_name):\n",
        "    os.remove(db_name)\n",
        "    print(f\"Removed existing database '{db_name}'.\")"
      ],
      "metadata": {
        "id": "Ihw9nW1UwO-o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "COLUMN_DATA_TYPES = {\n",
        "    'customers': {\n",
        "        'customer_id': 'int64',\n",
        "        'first_name': 'object',\n",
        "        'last_name': 'object',\n",
        "        'email': 'object',\n",
        "        'phone_number': 'object',\n",
        "        'address': 'object',\n",
        "        'city': 'object',\n",
        "        'country': 'object',\n",
        "        'postal_code': 'object',\n",
        "        'loyalty_points': 'int64'\n",
        "    },\n",
        "    'products': {\n",
        "        'product_id': 'int64',\n",
        "        'product_name': 'object',\n",
        "        'description': 'object',\n",
        "        'price': 'float64',\n",
        "        'discount_percentage': 'float64',\n",
        "        'category': 'object',\n",
        "        'brand': 'object',\n",
        "        'stock_quantity': 'int64',\n",
        "        'color': 'object',\n",
        "        'size': 'object',\n",
        "        'weight': 'float64',\n",
        "        'dimensions': 'object',\n",
        "        'release_date': 'datetime64[ns]',\n",
        "        'rating': 'float64',\n",
        "        'reviews_count': 'int64',\n",
        "        'seller_name': 'object',\n",
        "        'seller_rating': 'float64',\n",
        "        'seller_reviews_count': 'int64',\n",
        "        'shipping_method': 'object',\n",
        "        'shipping_cost': 'float64'\n",
        "    },\n",
        "    'orders': {\n",
        "        'order_id': 'int64',\n",
        "        'customer_id': 'int64',\n",
        "        'product_id': 'int64',\n",
        "        'quantity': 'int64',\n",
        "        'unit_price': 'float64',\n",
        "        'total_price': 'float64',\n",
        "        'order_date': 'datetime64[ns]',\n",
        "        'shipping_address': 'object',\n",
        "        'payment_method': 'object',\n",
        "        'status': 'object'\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Database setup ---\n",
        "db_name = 'ecommerce.db'\n",
        "conn = None  # Initialize connection to None\n",
        "\n",
        "try:\n",
        "    # Establish a connection to the SQLite database\n",
        "    conn = sqlite3.connect(db_name)\n",
        "    cursor = conn.cursor()\n",
        "    print(f\"Database '{db_name}' created and connected successfully. âœ…\")\n",
        "\n",
        "    # Create tables\n",
        "    cursor.execute(customers_schema)\n",
        "    cursor.execute(products_schema)\n",
        "    cursor.execute(orders_schema)\n",
        "    print(\"Tables 'customers', 'products', and 'orders' created successfully.\")\n",
        "\n",
        "    # --- Load data from CSV files into the tables using pandas ---\n",
        "    csv_to_table_map = {\n",
        "        '/content/customers.csv': 'customers',\n",
        "        '/content/products.csv': 'products',\n",
        "        '/content/orders.csv': 'orders'\n",
        "    }\n",
        "\n",
        "    for csv_file, table_name in csv_to_table_map.items():\n",
        "        if os.path.exists(csv_file):\n",
        "            print(f\"\\nProcessing '{csv_file}' for table '{table_name}'...\")\n",
        "\n",
        "            # Read the CSV file into a pandas DataFrame\n",
        "            df = pd.read_csv(csv_file)\n",
        "\n",
        "            # 1. Get the expected schema for the current table\n",
        "            expected_schema = COLUMN_DATA_TYPES[table_name]\n",
        "            expected_cols = list(expected_schema.keys())\n",
        "\n",
        "            # 2. Handle missing/extra columns\n",
        "            # Drop columns from DataFrame that are not in the schema\n",
        "            df = df[df.columns.intersection(expected_cols)]\n",
        "\n",
        "            # Add any missing columns and fill with None (which becomes NULL in SQL)\n",
        "            for col in expected_cols:\n",
        "                if col not in df.columns:\n",
        "                    df[col] = None\n",
        "\n",
        "            # 3. Reorder columns to match the defined schema exactly\n",
        "            df = df[expected_cols]\n",
        "\n",
        "            # 4. Enforce data types\n",
        "            for col, dtype in expected_schema.items():\n",
        "                if 'datetime' in dtype:\n",
        "                    # Use pd.to_datetime for date/time columns, coercing errors to NaT (Not a Time)\n",
        "                    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "                else:\n",
        "                    # Use astype for other columns, handling potential conversion errors\n",
        "                    try:\n",
        "                        df[col] = df[col].astype(dtype)\n",
        "                    except (ValueError, TypeError) as e:\n",
        "                        print(f\"  - Warning: Could not convert column '{col}' to {dtype}. Error: {e}. Leaving as is.\")\n",
        "\n",
        "\n",
        "            # Use the to_sql method to insert the cleaned DataFrame\n",
        "            df.to_sql(table_name, conn, if_exists='append', index=False)\n",
        "            print(f\"  -> Data from '{csv_file}' loaded into '{table_name}' table successfully.\")\n",
        "        else:\n",
        "            print(f\"Warning: '{csv_file}' not found. Skipping data load for '{table_name}'.\")\n",
        "\n",
        "    # Commit the changes to the database\n",
        "    conn.commit()\n",
        "    print(\"\\nData committed to the database successfully. ðŸŽ‰\")\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Database error: {e}\")\n",
        "except pd.errors.EmptyDataError as e:\n",
        "    print(f\"Pandas error: {e}. One of the CSV files might be empty.\")\n",
        "except KeyError as e:\n",
        "    print(f\"Schema definition error: A column is missing from the TABLE_DATA_TYPES dictionary: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "finally:\n",
        "    # Close the connection if it was established\n",
        "    if conn:\n",
        "        conn.close()\n",
        "        print(\"Database connection closed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK7GIAjvwT4Z",
        "outputId": "bed4d409-27e9-4b3b-de3f-a7d28ce34af9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database 'ecommerce.db' created and connected successfully. âœ…\n",
            "Tables 'customers', 'products', and 'orders' created successfully.\n",
            "\n",
            "Processing '/content/customers.csv' for table 'customers'...\n",
            "  -> Data from '/content/customers.csv' loaded into 'customers' table successfully.\n",
            "\n",
            "Processing '/content/products.csv' for table 'products'...\n",
            "  -> Data from '/content/products.csv' loaded into 'products' table successfully.\n",
            "\n",
            "Processing '/content/orders.csv' for table 'orders'...\n",
            "  - Warning: Could not convert column 'order_id' to int64. Error: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'. Leaving as is.\n",
            "  - Warning: Could not convert column 'customer_id' to int64. Error: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'. Leaving as is.\n",
            "  - Warning: Could not convert column 'quantity' to int64. Error: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'. Leaving as is.\n",
            "  -> Data from '/content/orders.csv' loaded into 'orders' table successfully.\n",
            "\n",
            "Data committed to the database successfully. ðŸŽ‰\n",
            "Database connection closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Install Gen AI Library **"
      ],
      "metadata": {
        "id": "F19bR6W44ImN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7LFeut14X6J",
        "outputId": "1ede4f27-d18b-4a84-a11b-df5f0c67540b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.41.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Required Modules**"
      ],
      "metadata": {
        "id": "GAfWv8rW5DnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "Fa1x-M_s5H11"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai_client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "b9qDJFhv5PDS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "### **ROLE**\n",
        "\n",
        "You are an expert-level SQLite Database Engineer specializing in Natural Language to SQL (NL2SQL) translation. Your sole function is to convert user questions written in plain English into accurate, efficient, and syntactically correct SQLite queries based on a fixed database schema.\n",
        "\n",
        "-----\n",
        "\n",
        "### **CONTEXT**\n",
        "\n",
        "You are the core translation engine for a business intelligence dashboard. This tool allows non-technical employees to query the company's e-commerce database using natural language. The database dialect is always **SQLite**. Your responses will be executed directly on the database.\n",
        "\n",
        "The database consists of the following three tables:\n",
        "\n",
        "**`customers` table:**\n",
        "\n",
        "```sql\n",
        "CREATE TABLE customers (\n",
        "    customer_id INT PRIMARY KEY,\n",
        "    first_name VARCHAR(50),\n",
        "    last_name VARCHAR(50),\n",
        "    email VARCHAR(50),\n",
        "    phone_number VARCHAR(50),\n",
        "    address VARCHAR(50),\n",
        "    city VARCHAR(50),\n",
        "    country VARCHAR(50),\n",
        "    postal_code VARCHAR(50),\n",
        "    loyalty_points INT\n",
        ");\n",
        "```\n",
        "\n",
        "**`products` table:**\n",
        "\n",
        "```sql\n",
        "CREATE TABLE products (\n",
        "    product_id INT PRIMARY KEY,\n",
        "    product_name TEXT,\n",
        "    description TEXT,\n",
        "    price DECIMAL(10,2),\n",
        "    discount_percentage DECIMAL(5,2),\n",
        "    category VARCHAR(50),\n",
        "    brand TEXT,\n",
        "    stock_quantity INT,\n",
        "    color VARCHAR(50),\n",
        "    size VARCHAR(20),\n",
        "    weight DECIMAL(5,2),\n",
        "    dimensions TEXT,\n",
        "    release_date DATE,\n",
        "    rating DECIMAL(3,1),\n",
        "    reviews_count INT,\n",
        "    seller_name TEXT,\n",
        "    seller_rating DECIMAL(3,1),\n",
        "    seller_reviews_count INT,\n",
        "    shipping_method VARCHAR(20),\n",
        "    shipping_cost DECIMAL(6,2)\n",
        ");\n",
        "```\n",
        "\n",
        "**`orders` table:**\n",
        "\n",
        "```sql\n",
        "CREATE TABLE orders (\n",
        "    order_id INT PRIMARY KEY,\n",
        "    customer_id INT,\n",
        "    product_id INT,\n",
        "    quantity INT,\n",
        "    unit_price DECIMAL(10,2),\n",
        "    total_price DECIMAL(10,2),\n",
        "    order_date DATE,\n",
        "    shipping_address VARCHAR(255),\n",
        "    payment_method VARCHAR(20),\n",
        "    status VARCHAR(20),\n",
        "    FOREIGN KEY (customer_id) REFERENCES customers(customer_id),\n",
        "    FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
        ");\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### **TASK**\n",
        "\n",
        "Your task is to receive a user's question in natural language and convert it into a single, executable SQLite query. Follow these steps meticulously:\n",
        "\n",
        "1.  **Analyze the User's Query:** Deconstruct the user's question to understand their core intent. Identify the specific data, conditions, aggregations (like `SUM`, `COUNT`, `AVG`), and ordering they are asking for.\n",
        "2.  **Map to the Schema:** Map the entities from the user's query to the appropriate tables (`customers`, `products`, `orders`) and columns. Determine the necessary `JOIN` operations using `customers.customer_id` and `products.product_id` as foreign keys in the `orders` table.\n",
        "3.  **Construct the SQLite Query:** Write a clean and efficient `SELECT` statement that is syntactically correct for SQLite. Ensure all table and column names are accurate.\n",
        "4.  **Handle Ambiguity:** If the user's query is vague, ambiguous, or lacks the necessary information to create a precise query, do not guess. Instead, formulate a specific, targeted question to ask the user for the missing information.\n",
        "\n",
        "-----\n",
        "\n",
        "### **CONSTRAINTS**\n",
        "\n",
        "  * **Read-Only Operations:** You must **ONLY** generate `SELECT` queries. Never generate `INSERT`, `UPDATE`, `DELETE`, `DROP`, or any other data-modifying statements.\n",
        "  * **Adhere Strictly to Schema:** Only use the tables and columns defined in the context. Do not invent or assume the existence of any other tables or columns.\n",
        "  * **No Explanations:** Do not add any conversational text or explanations about the query you generate. Your output must strictly follow the specified format.\n",
        "  * **Single Query Only:** The final output must be a single, complete, and executable SQL query.\n",
        "  * **Handle Impossibility:** If a request is impossible to fulfill with the given schema (e.g., \"Which employee made the most sales?\"), state clearly that the request cannot be completed and briefly explain why.\n",
        "\n",
        "-----\n",
        "\n",
        "### **EXAMPLES**\n",
        "\n",
        "**Example 1: Simple Lookup**\n",
        "\n",
        "  * **User Query:** \"Show me all customers who live in Noida\"\n",
        "  * **Expected Output:**\n",
        "    ```json\n",
        "    {\n",
        "      \"status\": \"success\",\n",
        "      \"response\": \"SELECT * FROM customers WHERE city = 'Noida';\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "**Example 2: Complex Join and Aggregation**\n",
        "\n",
        "  * **User Query:** \"What are the names of the top 3 products with the highest total revenue?\"\n",
        "  * **Expected Output:**\n",
        "    ```json\n",
        "    {\n",
        "      \"status\": \"success\",\n",
        "      \"response\": \"SELECT T2.product_name FROM orders AS T1 INNER JOIN products AS T2 ON T1.product_id = T2.product_id GROUP BY T2.product_name ORDER BY SUM(T1.total_price) DESC LIMIT 3;\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "**Example 3: Ambiguous Query**\n",
        "\n",
        "  * **User Query:** \"Show me recent orders\"\n",
        "  * **Expected Output:**\n",
        "    ```json\n",
        "    {\n",
        "      \"status\": \"clarification_needed\",\n",
        "      \"response\": \"Could you please define what 'recent' means? For example, 'in the last 7 days', 'this month', or 'since August 2025'.\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "**Example 4: Impossible Query**\n",
        "\n",
        "  * **User Query:** \"Which warehouse has the most stock?\"\n",
        "  * **Expected Output:**\n",
        "    ```json\n",
        "    {\n",
        "      \"status\": \"error\",\n",
        "      \"response\": \"I cannot answer this question as the database does not contain information about warehouses.\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "-----\n",
        "\n",
        "### **OUTPUT FORMAT**\n",
        "\n",
        "Your final response must be a single JSON object with two keys:\n",
        "\n",
        "1.  `\"status\"`: A string with one of three possible values: `\"success\"`, `\"clarification_needed\"`, or `\"error\"`.\n",
        "2.  `\"response\"`:\n",
        "      * If `status` is `\"success\"`, this will be a string containing the complete SQLite query.\n",
        "      * If `status` is `\"clarification_needed\"`, this will be a string containing the clarifying question for the user.\n",
        "      * If `status` is `\"error\"`, this will be a string explaining why the query could not be generated.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "80cP3O6Q6Dtc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def get_sql_query(genai_client, prompt, user_query):\n",
        "\n",
        "  # https://www.geeksforgeeks.org/python/formatted-string-literals-f-strings-python/\n",
        "  contents = f\"\"\"\n",
        "  {prompt}\n",
        "\n",
        "  Here's the user query in english you need to work on:\n",
        "  {user_query}\n",
        "  \"\"\"\n",
        "  response = genai_client.models.generate_content(model='gemini-2.5-flash', contents=contents)\n",
        "  # print(response)\n",
        "\n",
        "  # Access the usage_metadata attribute\n",
        "  usage_metadata = response.usage_metadata\n",
        "\n",
        "  # Print the different token counts\n",
        "  print(f\"Input Token Count: {usage_metadata.prompt_token_count}\")\n",
        "  print(f\"Thoughts Token Count: {response.usage_metadata.thoughts_token_count}\")\n",
        "  print(f\"Output Token Count: {usage_metadata.candidates_token_count}\")\n",
        "  print(f\"Total Token Count: {usage_metadata.total_token_count}\")\n",
        "\n",
        "  output = json.loads(response.text.replace('```json', '').replace('```', ''))\n",
        "\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "VY-_INyV6UKm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "def execute_query(query, db_name='ecommerce.db'):\n",
        "\n",
        "    conn = None\n",
        "    try:\n",
        "        # Connect to the database\n",
        "        conn = sqlite3.connect(db_name)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Execute the query\n",
        "        print(f\"\\nExecuting query on '{db_name}':\\n{query}\")\n",
        "        cursor.execute(query)\n",
        "\n",
        "        # Fetch all results\n",
        "        results = cursor.fetchall()\n",
        "\n",
        "        # Get column names from the cursor description\n",
        "        columns = [description[0] for description in cursor.description]\n",
        "\n",
        "        # Format results as a dataframe for easier use\n",
        "        results_as_dict = [dict(zip(columns, row)) for row in results]\n",
        "        results_df = pd.DataFrame(results_as_dict)\n",
        "\n",
        "        print(\"Query executed successfully.\")\n",
        "        return results_df\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"Database error executing query: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()"
      ],
      "metadata": {
        "id": "XnpYztLK6l6g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text2sql(genai_client, prompt, user_query):\n",
        "  output = get_sql_query(genai_client, prompt, user_query)\n",
        "  if output['status'] == 'success':\n",
        "    results = execute_query(output['response'])\n",
        "    return results\n",
        "  return output"
      ],
      "metadata": {
        "id": "4NDDqS-H6quU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2sql(genai_client, prompt, \"Show me the order count by country\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12DcBH7E6vnC",
        "outputId": "2d199561-cf54-42e3-b731-301ebda521ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Token Count: 1535\n",
            "Thoughts Token Count: 92\n",
            "Output Token Count: 73\n",
            "Total Token Count: 1700\n",
            "\n",
            "Executing query on 'ecommerce.db':\n",
            "SELECT T2.country, COUNT(T1.order_id) AS order_count FROM orders AS T1 INNER JOIN customers AS T2 ON T1.customer_id = T2.customer_id GROUP BY T2.country;\n",
            "Database error executing query: no such table: orders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2sql(genai_client, prompt, \"What are my most popular products\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-MiTT_062C4",
        "outputId": "6f1de26c-a221-48af-8586-ff8bd043d7dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Token Count: 1534\n",
            "Thoughts Token Count: 1145\n",
            "Output Token Count: 72\n",
            "Total Token Count: 2751\n",
            "\n",
            "Executing query on 'ecommerce.db':\n",
            "SELECT T2.product_name FROM orders AS T1 JOIN products AS T2 ON T1.product_id = T2.product_id GROUP BY T2.product_name ORDER BY SUM(T1.quantity) DESC;\n",
            "Database error executing query: no such table: orders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2sql(genai_client, prompt, \"which country ranks in middle by total sales??\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOsJaL2m68TC",
        "outputId": "39aaf6e1-7ff9-4952-c328-c277c70f9e6c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Token Count: 1537\n",
            "Thoughts Token Count: 1774\n",
            "Output Token Count: 184\n",
            "Total Token Count: 3495\n",
            "\n",
            "Executing query on 'ecommerce.db':\n",
            "WITH CountrySales AS (\n",
            "    SELECT\n",
            "        c.country,\n",
            "        SUM(o.total_price) AS total_sales\n",
            "    FROM customers AS c\n",
            "    JOIN orders AS o ON c.customer_id = o.customer_id\n",
            "    GROUP BY c.country\n",
            "),\n",
            "RankedCountries AS (\n",
            "    SELECT\n",
            "        country,\n",
            "        total_sales,\n",
            "        ROW_NUMBER() OVER (ORDER BY total_sales ASC) AS rank_asc,\n",
            "        COUNT(*) OVER () AS total_distinct_countries\n",
            "    FROM CountrySales\n",
            ")\n",
            "SELECT\n",
            "    country\n",
            "FROM RankedCountries\n",
            "WHERE\n",
            "    rank_asc = (total_distinct_countries + 1) / 2;\n",
            "Database error executing query: no such table: customers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2sql(genai_client, prompt, \"rank and count of sales of India by total sales??\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvN3xKgM7ECJ",
        "outputId": "ab9e4a39-976b-4dbb-ffc1-7fa520443ca6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Token Count: 1539\n",
            "Thoughts Token Count: 608\n",
            "Output Token Count: 70\n",
            "Total Token Count: 2217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'clarification_needed',\n",
              " 'response': 'Could you please specify what you would like to rank and count sales for within India? For example, are you interested in ranking customers in India by their total sales, or products sold in India, or perhaps cities within India?'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2sql(genai_client, prompt, \"Give me the order count by day of month\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTJC4mUZ7J4B",
        "outputId": "96182b10-d20b-496e-86a6-bafb440fed07"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Token Count: 1537\n",
            "Thoughts Token Count: 95\n",
            "Output Token Count: 66\n",
            "Total Token Count: 1698\n",
            "\n",
            "Executing query on 'ecommerce.db':\n",
            "SELECT strftime('%d', order_date) AS day_of_month, COUNT(order_id) AS order_count FROM orders GROUP BY day_of_month ORDER BY day_of_month;\n",
            "Database error executing query: no such table: orders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2sql(genai_client, prompt, \"On which day of the week do I get the most orders? Give me a detailed report.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpCdsoc_7NOL",
        "outputId": "97f56f1b-67dd-439b-c96f-e02c531021da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Token Count: 1547\n",
            "Thoughts Token Count: 301\n",
            "Output Token Count: 65\n",
            "Total Token Count: 1913\n",
            "\n",
            "Executing query on 'ecommerce.db':\n",
            "SELECT strftime('%A', order_date) AS day_of_week, COUNT(order_id) AS total_orders FROM orders GROUP BY day_of_week ORDER BY total_orders DESC;\n",
            "Database error executing query: no such table: orders\n"
          ]
        }
      ]
    }
  ]
}